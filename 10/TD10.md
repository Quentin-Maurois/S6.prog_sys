### Exercice 1 :
```shell
[quentin@LASTERIX hello-ubuntu]$ docker build -t hello-world:ubuntu-22.04 .
DEPRECATED: The legacy builder is deprecated and will be removed in a future release.
            Install the buildx component to build images with BuildKit:
            https://docs.docker.com/go/buildx/

Sending build context to Docker daemon  19.46kB
Step 1/4 : FROM ubuntu:22.04
 ---> 3b418d7b466a
Step 2/4 : LABEL tag="ubuntu-22.04"
 ---> Using cache
 ---> af6894fe0aef
Step 3/4 : COPY hello.exe /app/hello.exe
 ---> Using cache
 ---> 61ad3bb3d0f6
Step 4/4 : CMD ["/app/hello.exe"]
 ---> Using cache
 ---> 2c466cd79136
Successfully built 2c466cd79136
Successfully tagged hello-world:ubuntu-22.04
[quentin@LASTERIX hello-ubuntu]$ docker images
REPOSITORY    TAG            IMAGE ID       CREATED         SIZE
hello-world   ubuntu-22.04   2c466cd79136   4 minutes ago   77.8MB
ubuntu        22.04          3b418d7b466a   13 days ago     77.8MB
sonarqube     latest         db451e99d133   4 months ago    563MB
[quentin@LASTERIX hello-ubuntu]$ docker run hello-world:ubuntu-22.04
Hello, World!
```
Le nom et le tag sont spécifiés lors du build 


### Exercice 2 :
Si on reprends le même Dockerfile que pour ubuntu changeant juste la distro et le tag pour alpine, le programme ne connait pas printf. 


### Exercice 3 :
Comme vu en cours l'image alpine ne contient pas la bibliothèque c de base et il faut donc l'ajouter via la package manager d'alpine :
apk add gcompat
```shell
[quentin@LASTERIX hello-alpine]$ docker build -t hello-world:alpine-3.17 .
DEPRECATED: The legacy builder is deprecated and will be removed in a future release.
            Install the buildx component to build images with BuildKit:
            https://docs.docker.com/go/buildx/

Sending build context to Docker daemon  19.46kB
Step 1/5 : FROM alpine:3.17.3
 ---> 9ed4aefc74f6
Step 2/5 : LABEL tag="alpine-3.17"
 ---> Using cache
 ---> 10f4c17b14ab
Step 3/5 : RUN apk add gcompat
 ---> Using cache
 ---> 76870d0d43ef
Step 4/5 : COPY hello.exe /app/hello.exe
 ---> Using cache
 ---> 445e36c481ee
Step 5/5 : CMD ["/app/hello.exe"]
 ---> Using cache
 ---> 6b7adb0dee5b
Successfully built 6b7adb0dee5b
Successfully tagged hello-world:alpine-3.17
[quentin@LASTERIX hello-alpine]$ docker images
REPOSITORY    TAG            IMAGE ID       CREATED          SIZE
hello-world   alpine-3.17    6b7adb0dee5b   7 minutes ago    9.81MB
<none>        <none>         49c0cd2f1961   9 minutes ago    7.06MB
hello-world   ubuntu-22.04   5b32f2589ce1   25 minutes ago   77.8MB
ubuntu        22.04          3b418d7b466a   13 days ago      77.8MB
alpine        3.17.3         9ed4aefc74f6   5 weeks ago      7.04MB
sonarqube     latest         db451e99d133   4 months ago     563MB
[quentin@LASTERIX hello-alpine]$ docker run hello-world:alpine-3.17
Hello, World!
```


### Exercice 4 :
Comme prévu, le Dockerfile de ubuntu simplement adapté à scratch ne marche pas car le container ne connais pas la bibliothèque c. L'option la plus simple et la plus logique est de donner un programme avec des bibliothèques statiques au container. Si on voulait simplement utiliser des bibliothèques dynamiques on ne partirait pas de scratch car au final on aurait à installer à peu près les mêmes chose que dans alpine.

```shell
[quentin@LASTERIX hello-scratch]$ gcc -static -o hello.exe ../hello/hello.c
[quentin@LASTERIX hello-scratch]$ docker build -t hello-world:scratch .
DEPRECATED: The legacy builder is deprecated and will be removed in a future release.
            Install the buildx component to build images with BuildKit:
            https://docs.docker.com/go/buildx/

Sending build context to Docker daemon  749.6kB
Step 1/4 : FROM scratch
 ---> 
Step 2/4 : LABEL tag="scratch"
 ---> Running in 67afde535513
Removing intermediate container 67afde535513
 ---> 5701789f643f
Step 3/4 : COPY hello.exe /app/hello.exe
 ---> 320c05635e78
Step 4/4 : CMD ["/app/hello.exe"]
 ---> Running in c2bb5f3ca0ff
Removing intermediate container c2bb5f3ca0ff
 ---> 64018256acc3
Successfully built 64018256acc3
Successfully tagged hello-world:scratch
[quentin@LASTERIX hello-scratch]$ docker run hello-world:scratch
Hello, World!
```


### Exercice 5 :



### Exercice 6 :



### Exercice 7 :



### Exercice 8 :
```shell
    7.0 MB  FROM d56dd55284edabe                                                                                  
    160 MB  addgroup -g 1000 node     && adduser -u 1000 -G node -s /bin/sh -D node     && apk add --no-cache      
    7.8 MB  apk add --no-cache --virtual .build-deps-yarn curl gnupg tar   && for key in     6A010C5166006599AA17F 
     388 B  #(nop) COPY file:4d192565a7220e135cab6c77fbc1c73211b69f3d9fb37e62857b2c6eb9363d51 in /usr/local/bin/  
```
La première layer contient la distro utilisée (apline ici). 
La seconde layer contient les packages node
La troisième layer contient les packages alpine installés via apk add

### Exercice 9 :



### Exercice 10 :



### Exercice 11 :
Faire deux copy permet de copier en premier les packages qui changent rarement lors d'un développement et ensuite les fichiers de l'application qui changent lors du développement. Donc on se base sur les mêmes layers (avec alpine, packages, ... et les packages node) auxquelles on "empile" l'application. En ne faisant qu'un seul copy on se baserait sur la layer juste en dessous et on devrait alors ajouter les packages node à chaque nouvelle version (donc à chaque build)


### Exercice 12 :



### Exercice 13 :
Les deux solution sont : 
- passer les fichiers de temps de la machine hôte
- spécifier la timezone
Pour la première option, il suffit de partager ses fichiers de temps personnels et le container est directement synchronisé avec le temps de la machine hôte.
Pour la seconde option, il faut installer des packages pour alpine pour se synchroniser avec les seveurs de temps pour la timezone spécifiée. Cette méthode bien que plus lourde permet d'être sûr de la timezone utilisée.


### Exercice 14 :
```shell
[quentin@LASTERIX node]$ docker run --rm -it -v ./data:/data alpine:3.17 /bin/sh
/ # ls
bin    dev    home   media  opt    root   sbin   sys    usr
data   etc    lib    mnt    proc   run    srv    tmp    var
/ # cd data
/data # touch todel
/data # exit
[quentin@LASTERIX node]$ ls data
todel
```
Le fichier créé depuis le container a bien affecté le dossier sur la machine hôte


### Exercice 15 :
```shell
[quentin@LASTERIX node]$ docker run --rm -it -v voldata:/data alpine:3.17 /bin/sh
/ # ls
bin    dev    home   media  opt    root   sbin   sys    usr
data   etc    lib    mnt    proc   run    srv    tmp    var
/ # ls data
/ # touch data/todel
/ # echo toto>data/todel
/ # exit
[quentin@LASTERIX node]$ docker run --rm -it -v voldata:/data alpine:3.17 /bin/sh
/ # ls data
todel
/ # cat data/todel 
toto
/ # 
```
On voit bien que le fichier créé depuis le premier container a été sauvegardé dans le volume et est accessible depuis le second container


```shell
[quentin@LASTERIX ~]$ sudo su
[sudo] password for quentin: 
[root@LASTERIX quentin]# cd /var/lib/docker/volumes/voldata/_data
[root@LASTERIX _data]# ls
todel
```
L'emplacement réel où sont stockées les données n'est accessible que pour un super utilisateur pour des raisons de sécurité de docker.


### Exercice 16 :
```shell
[quentin@LASTERIX node]$ docker run -it node-app:18.16.0-alpine3.17 /bin/sh/app # whoami
root
/app # id
uid=0(root) gid=0(root) groups=0(root),1(bin),2(daemon),3(sys),4(adm),6(disk),10(wheel),11(floppy),20(dialout),26(tape),27(video)
/app # 
```
Sur le container, on est connecté en tant que root. 
On appartient aux groupes 0, 1, 2, 3, 4, 6, 10, 11, 20, 26, 27.
Le fait d'être root n'est pas vraiment un problèmen de sécurité car le container est isolé de la machine hôte.


### Exercice 17 :
Étrangement j'ai pu lancer le container avec un utilisateur sans avoir à rien changer.


### Exercice 18 :
